"""
CycleGAN vs CycleGAN+YOLO ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

ë‘ ëª¨ë¸ì„ ë™ì¼í•œ ì•¼ê°„ ì´ë¯¸ì§€ë¡œ í‰ê°€í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python compare_models.py --n_samples 100 --device 0
"""

import sys
import json
from pathlib import Path
import pandas as pd
import argparse
import numpy as np
import traceback

# run.pyì—ì„œ í•¨ìˆ˜ import
sys.path.insert(0, str(Path(__file__).parent))
from run import (
    sample_subset,
    run_cyclegan_b2a,
    run_cyclegan_a2b,
    prepare_for_yolo_val,
    run_yolo_val_api
)

PROJ = Path(__file__).parent

# ========== ì¤‘ì•™ ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨) ==========
# Baseline ëª¨ë¸ ì„¤ì •
BASELINE_CKPT_NAME = "clear_d2n_baseline_scalewidth_e100_k5k"
BASELINE_EPOCH = "latest"  # "latest" ë˜ëŠ” íŠ¹ì • ì—í­ ë²ˆí˜¸
BASELINE_NETG = "resnet_9blocks"

# Ours ëª¨ë¸ ì„¤ì •
OURS_CKPT_NAME = "clear_d2n_yolo_v3_lambda3_scalewidth_e100_k5k"
OURS_EPOCH = "latest"  # "latest" ë˜ëŠ” íŠ¹ì • ì—í­ ë²ˆí˜¸
OURS_NETG = "resnet_9blocks"

# ê³µí†µ ì„¤ì •
NORM = "instance"
NO_DROPOUT = True
USE_CROP = False  # scale_width ì‚¬ìš© (YOLO í‰ê°€ì— ìœ ë¦¬)
LOAD_SIZE = 1024  # ì¶”ë¡  í•´ìƒë„ ìƒí–¥ (256 -> 1024)
CROP_SIZE = 1024  # scale_width ëª¨ë“œì—ì„œëŠ” ì´ ê°’ì´ ë¦¬ì‚¬ì´ì§• ê¸°ì¤€ì´ ë¨
# ===============================================


def compare_models(n_samples=100, device='0', yolo_model='yolo11s.pt'):
    """
    ë‘ CycleGAN ëª¨ë¸ì„ ë¹„êµí•©ë‹ˆë‹¤.
    
    Args:
        n_samples: í‰ê°€í•  ìƒ˜í”Œ ê°œìˆ˜
        device: GPU device ID
        yolo_model: YOLO ëª¨ë¸ ê²½ë¡œ
    """
    print("\n" + "="*60)
    print("  CycleGAN vs CycleGAN+YOLO ë¹„êµ ì‹¤í—˜")
    print("="*60 + "\n")
    
    # ì‹¤í—˜ ë””ë ‰í„°ë¦¬ ì´ˆê¸°í™” (ê¸°ì¡´ ê²°ê³¼ ì‚­ì œ)
    exp_root = PROJ / "comparison_results"
    if exp_root.exists():
        print("ğŸ—‘ï¸  ê¸°ì¡´ comparison_results í´ë” ì‚­ì œ ì¤‘...")
        import shutil
        shutil.rmtree(exp_root)
        print("âœ“ ì‚­ì œ ì™„ë£Œ\n")
    exp_root.mkdir(exist_ok=True)
    
    # ========== 1. ë°ì´í„° ìƒ˜í”Œë§ (Night & Day) ==========
    print("ğŸ“‚ Step 1: ë°ì´í„° ìƒ˜í”Œë§ (Night & Day)...")
    
    # 1-1. Night Sampling
    night_src = PROJ / "datasets" / "yolo_bdd100k" / "clear_night"
    night_input = exp_root / "inputs" / "night"
    
    sample_subset(
        src_root=night_src,
        dest_root=night_input,
        n_samples=n_samples,
        copy_labels=True
    )
    
    # 1-2. Day Sampling (for Reference)
    day_src = PROJ / "datasets" / "yolo_bdd100k" / "clear_daytime"
    day_input = exp_root / "inputs" / "day"
    
    # Day ì´ë¯¸ì§€ëŠ” Nightì™€ 1:1 ë§¤ì¹­ì´ ì•„ë‹ˆë¯€ë¡œ ëœë¤ ìƒ˜í”Œë§
    sample_subset(
        src_root=day_src,
        dest_root=day_input,
        n_samples=n_samples,
        copy_labels=True
    )
    
    print(f"âœ“ {n_samples}ê°œ ìƒ˜í”Œ ì¤€ë¹„ ì™„ë£Œ (Night & Day)\n")

    
    # ========== 2. Baseline ëª¨ë¸ë¡œ ë³€í™˜ ==========
    print("ğŸ”„ Step 2: Baseline (ìˆœìˆ˜ CycleGAN) ë³€í™˜...")
    
    baseline_out = exp_root / "outputs" / "baseline"
    
    # ê¸°ì¡´ ì²´í¬í¬ì¸íŠ¸ í™•ì¸
    baseline_ckpt = PROJ / "pytorch-CycleGAN-and-pix2pix" / "checkpoints" / BASELINE_CKPT_NAME
    if not baseline_ckpt.exists():
        print("âš ï¸  Baseline ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ!")
        print(f"    {baseline_ckpt}")
        print("    TRAIN_BASELINE.batì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.\n")
        return None
    
    run_cyclegan_b2a(
        input_dir=night_input / "images",
        results_root=baseline_out,
        ckpt_name=BASELINE_CKPT_NAME,
        norm=NORM,
        no_dropout=NO_DROPOUT,
        netG=BASELINE_NETG,
        use_crop=USE_CROP,
        epoch=BASELINE_EPOCH,
        load_size=LOAD_SIZE,
        crop_size=CROP_SIZE
    )
    
    print("âœ“ Baseline ë³€í™˜ ì™„ë£Œ\n")
    
    # ========== 3. YOLO ëª¨ë¸ë¡œ ë³€í™˜ ==========
    print("ğŸ”„ Step 3: Ours (CycleGAN+YOLO) ë³€í™˜...")
    
    yolo_out = exp_root / "outputs" / "yolo"
    
    # Ours ëª¨ë¸ì€ cyclegan_yolo_clear_d2n ë°ì´í„°ì…‹(A=Night, B=Day)ìœ¼ë¡œ í•™ìŠµë¨
    # ë”°ë¼ì„œ Night->Day ë³€í™˜ì„ ìœ„í•´ G_A (A->B)ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨
    run_cyclegan_a2b(
        input_dir=night_input / "images",
        results_root=yolo_out,
        ckpt_name=OURS_CKPT_NAME,
        norm=NORM,
        no_dropout=NO_DROPOUT,
        netG=OURS_NETG,
        use_crop=USE_CROP,
        epoch=OURS_EPOCH,
        load_size=LOAD_SIZE,
        crop_size=CROP_SIZE
    )
    
    print("âœ“ YOLO ëª¨ë¸ ë³€í™˜ ì™„ë£Œ\n")
    
    # ========== 4. YOLO í‰ê°€ ì¤€ë¹„ ==========
    print("ğŸ“‹ Step 4: YOLO í‰ê°€ ì¤€ë¹„...")
    
    # Baseline
    baseline_yolo = exp_root / "yolo_eval" / "baseline"
    baseline_test_folder = "test_latest" if BASELINE_EPOCH == "latest" else f"test_{BASELINE_EPOCH}"
    prepare_for_yolo_val(
        img_dir=baseline_out / BASELINE_CKPT_NAME / baseline_test_folder / "images",
        label_dir=night_input / "labels",
        output_dir=baseline_yolo
    )
    
    # YOLO ëª¨ë¸
    yolo_yolo = exp_root / "yolo_eval" / "yolo"
    ours_test_folder = "test_latest" if OURS_EPOCH == "latest" else f"test_{OURS_EPOCH}"
    prepare_for_yolo_val(
        img_dir=yolo_out / OURS_CKPT_NAME / ours_test_folder / "images",
        label_dir=night_input / "labels",
        output_dir=yolo_yolo
    )
    
    print("âœ“ í‰ê°€ ì¤€ë¹„ ì™„ë£Œ\n")
    
    # ========== 5. YOLO í‰ê°€ ì‹¤í–‰ ==========
    print("ğŸ¯ Step 5: YOLO í‰ê°€ ì‹¤í–‰...\n")
    
    # 5-0. Original Day (Reference)
    print("  [1/4] Original Day (Reference) í‰ê°€...")
    metrics_day = run_yolo_val_api(
        model_path=Path(yolo_model),
        data_yaml=day_input / "data.yaml",
        split="test",
        imgsz=1280,
        device=device,
        save_dir=exp_root / "yolo_results" / "day"
    )

    # 5-1. Original Night
    print("\n  [2/4] Original Night í‰ê°€...")
    metrics_original = run_yolo_val_api(
        model_path=Path(yolo_model),
        data_yaml=night_input / "data.yaml",
        split="test",
        imgsz=1280,
        device=device,
        save_dir=exp_root / "yolo_results" / "original",
        save_txt=True,
        save_conf=True
    )
    
    # 5-2. Baseline
    print("\n  [3/4] Baseline í‰ê°€...")
    metrics_baseline = run_yolo_val_api(
        model_path=Path(yolo_model),
        data_yaml=baseline_yolo / "data.yaml",
        split="test",
        imgsz=1280,
        device=device,
        save_dir=exp_root / "yolo_results" / "baseline",
        save_txt=True,
        save_conf=True
    )
    
    # 5-3. YOLO ëª¨ë¸
    print("\n  [4/4] Ours (CycleGAN+YOLO) í‰ê°€...")
    metrics_yolo = run_yolo_val_api(
        model_path=Path(yolo_model),
        data_yaml=yolo_yolo / "data.yaml",
        split="test",
        imgsz=1280,
        device=device,
        save_dir=exp_root / "yolo_results" / "yolo",
        save_txt=True,
        save_conf=True
    )
    
    # ========== 6. Ensemble í‰ê°€ (New!) ==========
    print("\nğŸ¯ Step 6: Ensemble í‰ê°€ ì‹¤í–‰ (Night + Ours)...")
    try:
        from ensemble_eval import evaluate_ensemble
        import traceback
        
        # GT Dir (from inputs/night/labels)
        gt_dir = night_input / "labels"
        
        # Helper to find labels dir
        def find_labels_dir(base_dir):
            if (base_dir / "labels").exists():
                return base_dir / "labels"
            # Try recursive search for 'labels' dir
            found = list(base_dir.rglob("labels"))
            if found:
                # Prefer the one closest to root? or just first
                return found[0]
            return base_dir # Fallback

        # Pred Dirs (Ultralytics saves labels in save_dir/labels)
        night_pred_dir = find_labels_dir(metrics_original['save_dir'])
        ours_pred_dir = find_labels_dir(metrics_yolo['save_dir'])
        
        print(f"  GT Dir: {gt_dir}")
        print(f"  Night Pred Dir: {night_pred_dir} (Exists: {night_pred_dir.exists()})")
        print(f"  Ours Pred Dir: {ours_pred_dir} (Exists: {ours_pred_dir.exists()})")
        
        if night_pred_dir.exists() and ours_pred_dir.exists():
            # CRITICAL: conf_thres=0.25 (test_ensemble.pyì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
            # 0.001ë¡œ ì„¤ì •í•˜ë©´ Ours ëª¨ë¸ì˜ False Positiveê°€ ë„ˆë¬´ ë§ì´ í¬í•¨ë˜ì–´ mAPê°€ í•˜ë½í•¨
            ensemble_save_dir = exp_root / "yolo_results" / "ensemble"
            
            # Define class names (BDD100K)
            NAMES = ["person", "rider", "car", "bus", "truck", "bike", "motor", "traffic light", "traffic sign", "train"]
            
            ensemble_metrics = evaluate_ensemble(
                gt_dir=gt_dir,
                pred_dirs=[night_pred_dir, ours_pred_dir],
                img_dir=night_input / "images",
                names=NAMES,
                img_w=1280, img_h=720,
                iou_thres=0.5, conf_thres=0.25,
                save_dir=ensemble_save_dir
            )
            # evaluate_ensemble returns dict {'mAP50': float, 'precision': float, 'recall': float}
            metrics_ensemble = ensemble_metrics
        else:
            print("âš ï¸  Warning: Prediction labels not found. Skipping ensemble.")
            metrics_ensemble = {'mAP50': 0.0, 'precision': 0.0, 'recall': 0.0}
            
    except ImportError:
        print("âš ï¸  Warning: ensemble_eval module not found.")
        metrics_ensemble = {'mAP50': 0.0, 'precision': 0.0, 'recall': 0.0}
    except Exception as e:
        print(f"âš ï¸  Ensemble evaluation failed: {e}")
        traceback.print_exc()
        metrics_ensemble = {'mAP50': 0.0, 'precision': 0.0, 'recall': 0.0}

    print("\nâœ“ í‰ê°€ ì™„ë£Œ\n")
    
    # ========== 7. ê²°ê³¼ ë¹„êµ ==========
    print("="*60)
    print("  ğŸ“Š ë¹„êµ ê²°ê³¼")
    print("="*60 + "\n")
    
    # Helper function for safe division
    def safe_improvement(val1, val2):
        if val2 == 0 or val2 is None:
            return "N/A"
        return f"+{(val1 - val2) / val2 * 100:.1f}%"
    
    # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
    results = {
        'Model': [
            'Original (Day)',
            'Original (Night)',
            'Baseline (CycleGAN)',
            'Ours (CycleGAN+YOLO)',
            'Ensemble (Night+Ours)',
            'Improvement (Ours vs Baseline)'
        ],
        'mAP50': [
            f"{metrics_day['mAP50']:.4f}" if metrics_day['mAP50'] is not None else "N/A",
            f"{metrics_original['mAP50']:.4f}" if metrics_original['mAP50'] is not None else "N/A",
            f"{metrics_baseline['mAP50']:.4f}" if metrics_baseline['mAP50'] is not None else "N/A",
            f"{metrics_yolo['mAP50']:.4f}" if metrics_yolo['mAP50'] is not None else "N/A",
            f"{metrics_ensemble['mAP50']:.4f}",
            safe_improvement(metrics_yolo['mAP50'], metrics_baseline['mAP50'])
        ],
        'Precision': [
            f"{metrics_day['precision']:.4f}" if metrics_day['precision'] is not None else "N/A",
            f"{metrics_original['precision']:.4f}" if metrics_original['precision'] is not None else "N/A",
            f"{metrics_baseline['precision']:.4f}" if metrics_baseline['precision'] is not None else "N/A",
            f"{metrics_yolo['precision']:.4f}" if metrics_yolo['precision'] is not None else "N/A",
            f"{metrics_ensemble['precision']:.4f}",
            safe_improvement(metrics_yolo['precision'], metrics_baseline['precision'])
        ],
        'Recall': [
            f"{metrics_day['recall']:.4f}" if metrics_day['recall'] is not None else "N/A",
            f"{metrics_original['recall']:.4f}" if metrics_original['recall'] is not None else "N/A",
            f"{metrics_baseline['recall']:.4f}" if metrics_baseline['recall'] is not None else "N/A",
            f"{metrics_yolo['recall']:.4f}" if metrics_yolo['recall'] is not None else "N/A",
            f"{metrics_ensemble['recall']:.4f}",
            safe_improvement(metrics_yolo['recall'], metrics_baseline['recall'])
        ]
    }
    
    df = pd.DataFrame(results)
    print(df.to_string(index=False))
    print()
    
    # ê²°ê³¼ ì €ì¥
    csv_path = exp_root / "comparison_results.csv"
    df.to_csv(csv_path, index=False)
    print(f"âœ“ ê²°ê³¼ ì €ì¥: {csv_path}\n")
    
    # JSON ì €ì¥
    # Helper to convert numpy types to python types
    def convert_to_serializable(obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, Path):
            return str(obj)
        return obj

    # Convert metrics_ensemble values to float
    metrics_ensemble_serializable = {k: float(v) for k, v in metrics_ensemble.items()}

    summary = {
        'day': {k: float(v) if v is not None and not isinstance(v, Path) else 0.0 for k, v in metrics_day.items() if k != 'save_dir'},
        'original': {k: float(v) if v is not None and not isinstance(v, Path) else 0.0 for k, v in metrics_original.items() if k != 'save_dir'},
        'baseline': {k: float(v) if v is not None and not isinstance(v, Path) else 0.0 for k, v in metrics_baseline.items() if k != 'save_dir'},
        'yolo': {k: float(v) if v is not None and not isinstance(v, Path) else 0.0 for k, v in metrics_yolo.items() if k != 'save_dir'},
        'ensemble': metrics_ensemble_serializable,
        'improvement': {}
    }

    
    # Safe improvement calculation
    for metric in ['mAP50', 'mAP50-95', 'precision', 'recall']:
        base_val = metrics_baseline.get(metric, 0.0) or 0.0
        yolo_val = metrics_yolo.get(metric, 0.0) or 0.0
        
        if base_val > 0:
            summary['improvement'][metric] = (yolo_val - base_val) / base_val * 100
        else:
            summary['improvement'][metric] = None
    
    json_path = exp_root / "comparison_summary.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2)
    
    print(f"âœ“ ìš”ì•½ ì €ì¥: {json_path}\n")
    
    # ========== 7. í•´ì„ ==========
    print("="*60)
    print("  ğŸ’¡ ê²°ê³¼ í•´ì„")
    print("="*60 + "\n")
    
    # mAP50 ê¸°ì¤€ ë¶„ì„ (safe version)
    orig_map = metrics_original['mAP50'] or 0.0
    base_map = metrics_baseline['mAP50'] or 0.0
    yolo_map = metrics_yolo['mAP50'] or 0.0
    
    if orig_map > 0 and base_map > 0 and yolo_map > 0:
        base_drop = (orig_map - base_map) / orig_map * 100
        yolo_drop = (orig_map - yolo_map) / orig_map * 100
        improvement = (yolo_map - base_map) / base_map * 100
        
        print(f"ì›ë³¸ ëŒ€ë¹„ ì„±ëŠ¥ í•˜ë½:")
        print(f"  - Baseline: {base_drop:.1f}% í•˜ë½ (mAP50: {orig_map:.3f} â†’ {base_map:.3f})")
        print(f"  - Ours:     {yolo_drop:.1f}% í•˜ë½ (mAP50: {orig_map:.3f} â†’ {yolo_map:.3f})")
        print()
        print(f"Baseline ëŒ€ë¹„ ê°œì„ :")
        print(f"  - ìƒëŒ€ì  ê°œì„ ìœ¨: +{improvement:.1f}%")
        print(f"  - ì ˆëŒ€ì  ê°œì„ : {yolo_map - base_map:.4f}")
        print()
        
        if improvement > 50:
            print("âœ… ê²°ë¡ : YOLO Lossê°€ ê°ì²´ êµ¬ì¡° ë³´ì¡´ì— **ë§¤ìš° íš¨ê³¼ì **ì…ë‹ˆë‹¤!")
        elif improvement > 20:
            print("âœ… ê²°ë¡ : YOLO Lossê°€ ê°ì²´ êµ¬ì¡° ë³´ì¡´ì— **íš¨ê³¼ì **ì…ë‹ˆë‹¤!")
        elif improvement > 0:
            print("âš ï¸  ê²°ë¡ : YOLO Lossê°€ ì•½ê°„ ë„ì›€ì´ ë˜ì§€ë§Œ, ê°œì„  í­ì´ ì‘ìŠµë‹ˆë‹¤.")
        else:
            print("âŒ ê²°ë¡ : YOLO Lossê°€ ê¸°ëŒ€ë§Œí¼ íš¨ê³¼ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”.")
            
        # Ensemble Analysis
        ensemble_map = metrics_ensemble['mAP50']
        if ensemble_map > orig_map:
            ens_imp = (ensemble_map - orig_map) / orig_map * 100
            print(f"\nğŸš€ Ensemble íš¨ê³¼:")
            print(f"  - Original ëŒ€ë¹„: +{ens_imp:.1f}% í–¥ìƒ (mAP50: {orig_map:.3f} â†’ {ensemble_map:.3f})")
            print("  - ê²°ë¡ : Night + Fake Day ì•™ìƒë¸”ì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ í›¨ì”¬ ê°•ë ¥í•©ë‹ˆë‹¤!")
            
    else:
        print("âš ï¸  ê²½ê³ : í•˜ë‚˜ ì´ìƒì˜ ë©”íŠ¸ë¦­ì´ 0ì…ë‹ˆë‹¤. í‰ê°€ ë°ì´í„° ë˜ëŠ” ëª¨ë¸ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print(f"  - Original: {orig_map:.4f}")
        print(f"  - Baseline: {base_map:.4f}")
        print(f"  - Ours:     {yolo_map:.4f}")

    
    print()
    print("="*60)
    
    print()
    print("="*60)
    print(f"  ğŸ“ ê²°ê³¼ ìœ„ì¹˜: {exp_root}")
    print("="*60 + "\n")
    
    return summary


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="CycleGAN vs CycleGAN+YOLO ë¹„êµ")
    parser.add_argument('--n_samples', type=int, default=100,
                        help='í‰ê°€í•  ìƒ˜í”Œ ê°œìˆ˜ (ê¸°ë³¸: 100)')
    parser.add_argument('--device', type=str, default='0',
                        help='GPU device ID (ê¸°ë³¸: 0)')
    parser.add_argument('--yolo_model', type=str, default='yolo11s.pt',
                        help='YOLO ëª¨ë¸ ê²½ë¡œ (ê¸°ë³¸: yolo11s.pt)')
    
    args = parser.parse_args()
    
    compare_models(
        n_samples=args.n_samples,
        device=args.device,
        yolo_model=args.yolo_model
    )
